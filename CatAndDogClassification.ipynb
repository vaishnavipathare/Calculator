{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnavipathare/Calculator/blob/main/CatAndDogClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfY93JfW7_DK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's break down the parameters used in the `ImageDataGenerator`:\n",
        "\n",
        "1. **rescale=1./255:**\n",
        "   - This parameter scales the pixel values of the images. By dividing each pixel value by 255, it normalizes the values to be in the range [0, 1]. This is a common preprocessing step in deep learning to ensure numerical stability.\n",
        "\n",
        "2. **shear_range=0.2:**\n",
        "   - Shear transformation tilts the image along its axis. This parameter controls the intensity of shear. In this case, it is set to 0.2, meaning that the shear angle can vary up to 0.2 radians.\n",
        "\n",
        "3. **zoom_range=0.2:**\n",
        "   - Zoom transformation randomly zooms into the image. The zoom range parameter sets the range for the zoom. Here, it is set to 0.2, indicating that the image can be zoomed in or out by up to 20%.\n",
        "\n",
        "4. **horizontal_flip=True:**\n",
        "   - Horizontal flip randomly flips the image horizontally. Setting this parameter to `True` enables horizontal flipping, which can provide more variability in the training data. This is useful for tasks where the orientation of the object in the image does not affect its classification.\n",
        "\n",
        "In summary, the `ImageDataGenerator` is configured to perform data augmentation on the input images during the training process. Data augmentation is a technique used to artificially increase the size of the training dataset by applying various transformations to the existing images, helping the model generalize better and become more robust to different variations in the input data."
      ],
      "metadata": {
        "id": "barQjW2FNfMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip= True)\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Cat_and_Dog/train',\n",
        "                                                 target_size = (64,64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXe3L-Ml8UgH",
        "outputId": "4411e97c-17a5-4391-a31e-2016b8551314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 557 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip= True)\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Cat_and_Dog/test',\n",
        "                                                 target_size = (64,64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xiVUXWk-GOj",
        "outputId": "7b20f7e5-0184-458a-cf1c-5801d9669ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "BVo3vcLT-e9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `filters`: This specifies the number of filters (also known as kernels) in the convolutional layer. In this case, you have set it to 32, meaning there will be 32 filters in this layer.\n",
        "\n",
        "- `kernel_size`: This parameter defines the size of the convolutional kernel (or filter). You've set it to 3, indicating that each filter will have a 3x3 size.\n",
        "\n",
        "- `activation`: The activation function used in the layer. In this case, it's set to 'relu', which means Rectified Linear Unit (ReLU) activation will be applied after the convolution operation.\n",
        "\n",
        "- `input_shape`: This specifies the input shape for the first layer in your neural network. In this example, you're using an input shape of [64, 64, 3], which implies that your input data is expected to have dimensions of 64x64 pixels and 3 color channels (e.g., for RGB images)."
      ],
      "metadata": {
        "id": "A8OeKw4n_teZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Layer"
      ],
      "metadata": {
        "id": "cZxG9x_BDaCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',\n",
        "                               input_shape=[64,64,3]))"
      ],
      "metadata": {
        "id": "rI7VlYX8-uGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `pool_size`: This parameter specifies the size of the pooling window. In your code, you've set it to 2, which means that a 2x2 window will be used for pooling. During max-pooling, the maximum value in each 2x2 window of the input will be retained, and the other values will be discarded.\n",
        "\n",
        "- `strides`: This parameter determines the stride of the pooling operation. In your code, it's also set to 2, which means that the pooling window will move 2 units at a time in both the horizontal and vertical directions. This reduces the size of the feature maps, effectively downsampling the data.\n",
        "\n",
        "The MaxPooling2D layer is often used in CNNs to reduce the spatial dimensions of the feature maps produced by convolutional layers, helping to capture important features while reducing computational complexity."
      ],
      "metadata": {
        "id": "kQIrSgXkBGTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
      ],
      "metadata": {
        "id": "tgjUk0zfAmT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Layer"
      ],
      "metadata": {
        "id": "WDFefJebDUzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',\n",
        "                               input_shape=[64,64,3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "Xtl9xcxHCPxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flattening"
      ],
      "metadata": {
        "id": "5Y0kuaIfDjwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "fuPs7_XGDHyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full Connection"
      ],
      "metadata": {
        "id": "QaSBe_9kDfx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units= 128,activation='relu'))"
      ],
      "metadata": {
        "id": "VhG9rQeRDQ8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output Layer"
      ],
      "metadata": {
        "id": "-F75gBAREEz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units= 1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Uub1UqhsEDOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qRkYKQGEX15",
        "outputId": "45e42cd8-ff0e-454b-b85c-8d70ac5102f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 813217 (3.10 MB)\n",
            "Trainable params: 813217 (3.10 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the CNN"
      ],
      "metadata": {
        "id": "6AcG2xKEEfWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "             loss='binary_crossentropy',\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "u5mjazxEEahs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKpUfB7oExFO",
        "outputId": "0f9a0323-e220-4978-996c-a38ba65bfa39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "18/18 [==============================] - 178s 10s/step - loss: 0.7334 - accuracy: 0.5206 - val_loss: 0.6954 - val_accuracy: 0.5214\n",
            "Epoch 2/25\n",
            "18/18 [==============================] - 11s 603ms/step - loss: 0.6882 - accuracy: 0.5745 - val_loss: 0.6893 - val_accuracy: 0.5643\n",
            "Epoch 3/25\n",
            "18/18 [==============================] - 11s 593ms/step - loss: 0.6714 - accuracy: 0.5799 - val_loss: 0.7174 - val_accuracy: 0.4857\n",
            "Epoch 4/25\n",
            "18/18 [==============================] - 10s 574ms/step - loss: 0.6622 - accuracy: 0.6158 - val_loss: 0.7102 - val_accuracy: 0.5429\n",
            "Epoch 5/25\n",
            "18/18 [==============================] - 10s 553ms/step - loss: 0.6532 - accuracy: 0.6086 - val_loss: 0.6956 - val_accuracy: 0.5714\n",
            "Epoch 6/25\n",
            "18/18 [==============================] - 11s 618ms/step - loss: 0.6249 - accuracy: 0.6625 - val_loss: 0.6980 - val_accuracy: 0.5357\n",
            "Epoch 7/25\n",
            "18/18 [==============================] - 10s 589ms/step - loss: 0.6017 - accuracy: 0.6768 - val_loss: 0.6809 - val_accuracy: 0.6286\n",
            "Epoch 8/25\n",
            "18/18 [==============================] - 10s 544ms/step - loss: 0.5806 - accuracy: 0.6840 - val_loss: 0.6986 - val_accuracy: 0.6000\n",
            "Epoch 9/25\n",
            "18/18 [==============================] - 11s 618ms/step - loss: 0.5523 - accuracy: 0.7181 - val_loss: 0.6972 - val_accuracy: 0.6714\n",
            "Epoch 10/25\n",
            "18/18 [==============================] - 10s 539ms/step - loss: 0.5348 - accuracy: 0.7307 - val_loss: 0.6638 - val_accuracy: 0.6071\n",
            "Epoch 11/25\n",
            "18/18 [==============================] - 10s 538ms/step - loss: 0.5195 - accuracy: 0.7253 - val_loss: 0.7155 - val_accuracy: 0.6643\n",
            "Epoch 12/25\n",
            "18/18 [==============================] - 9s 524ms/step - loss: 0.5172 - accuracy: 0.7289 - val_loss: 0.6592 - val_accuracy: 0.6929\n",
            "Epoch 13/25\n",
            "18/18 [==============================] - 11s 603ms/step - loss: 0.5028 - accuracy: 0.7451 - val_loss: 0.5994 - val_accuracy: 0.6929\n",
            "Epoch 14/25\n",
            "18/18 [==============================] - 10s 544ms/step - loss: 0.4822 - accuracy: 0.7522 - val_loss: 0.6931 - val_accuracy: 0.6500\n",
            "Epoch 15/25\n",
            "18/18 [==============================] - 10s 543ms/step - loss: 0.4741 - accuracy: 0.7630 - val_loss: 0.6629 - val_accuracy: 0.6643\n",
            "Epoch 16/25\n",
            "18/18 [==============================] - 12s 681ms/step - loss: 0.4707 - accuracy: 0.7792 - val_loss: 0.6688 - val_accuracy: 0.6571\n",
            "Epoch 17/25\n",
            "18/18 [==============================] - 11s 602ms/step - loss: 0.4228 - accuracy: 0.8115 - val_loss: 0.6728 - val_accuracy: 0.6214\n",
            "Epoch 18/25\n",
            "18/18 [==============================] - 9s 516ms/step - loss: 0.4605 - accuracy: 0.7738 - val_loss: 0.6779 - val_accuracy: 0.6571\n",
            "Epoch 19/25\n",
            "18/18 [==============================] - 10s 537ms/step - loss: 0.4251 - accuracy: 0.8043 - val_loss: 0.7739 - val_accuracy: 0.6571\n",
            "Epoch 20/25\n",
            "18/18 [==============================] - 9s 505ms/step - loss: 0.4223 - accuracy: 0.7828 - val_loss: 0.6172 - val_accuracy: 0.6714\n",
            "Epoch 21/25\n",
            "18/18 [==============================] - 10s 550ms/step - loss: 0.4020 - accuracy: 0.8025 - val_loss: 0.7050 - val_accuracy: 0.6786\n",
            "Epoch 22/25\n",
            "18/18 [==============================] - 10s 547ms/step - loss: 0.3666 - accuracy: 0.8294 - val_loss: 0.6264 - val_accuracy: 0.7143\n",
            "Epoch 23/25\n",
            "18/18 [==============================] - 9s 475ms/step - loss: 0.3943 - accuracy: 0.8348 - val_loss: 0.5800 - val_accuracy: 0.7286\n",
            "Epoch 24/25\n",
            "18/18 [==============================] - 10s 545ms/step - loss: 0.3391 - accuracy: 0.8510 - val_loss: 0.7675 - val_accuracy: 0.6571\n",
            "Epoch 25/25\n",
            "18/18 [==============================] - 10s 544ms/step - loss: 0.3065 - accuracy: 0.8815 - val_loss: 0.7248 - val_accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79a7d0cad360>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "test_image = tf.keras.utils.load_img('/content/drive/MyDrive/Cat_and_Dog/test/cats/cat_1.jpg',\n",
        "                                     target_size= (64,64))"
      ],
      "metadata": {
        "id": "FMxqS2yDE-2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "lV7xPwptHAiJ",
        "outputId": "dcb40423-72c8-400c-d093-86de5df24903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = tf.keras.utils.img_to_array(test_image)"
      ],
      "metadata": {
        "id": "Yrofn2cOHCEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = np.expand_dims(test_image,axis=0)\n",
        "test_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q8dH8GUHZ5O",
        "outputId": "97fdb9ed-002b-4c48-ac09-0afaf84bd475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 97., 139., 153.],\n",
              "         [113., 147., 157.],\n",
              "         [124., 147., 163.],\n",
              "         ...,\n",
              "         [ 67., 137., 149.],\n",
              "         [ 67., 135., 146.],\n",
              "         [ 76., 140., 152.]],\n",
              "\n",
              "        [[ 94., 140., 156.],\n",
              "         [ 95., 141., 157.],\n",
              "         [112., 145., 160.],\n",
              "         ...,\n",
              "         [ 42., 122., 133.],\n",
              "         [ 59., 133., 144.],\n",
              "         [ 73., 139., 151.]],\n",
              "\n",
              "        [[ 91., 137., 153.],\n",
              "         [ 93., 139., 155.],\n",
              "         [114., 146., 161.],\n",
              "         ...,\n",
              "         [ 61., 136., 142.],\n",
              "         [ 57., 131., 142.],\n",
              "         [ 65., 135., 145.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[  2.,   0.,   1.],\n",
              "         [  3.,   1.,   2.],\n",
              "         [  0.,   0.,   0.],\n",
              "         ...,\n",
              "         [ 60.,  41.,  37.],\n",
              "         [ 63.,  46.,  38.],\n",
              "         [ 68.,  44.,  40.]],\n",
              "\n",
              "        [[ 26.,  18.,  15.],\n",
              "         [ 26.,  18.,  15.],\n",
              "         [ 18.,  15.,  10.],\n",
              "         ...,\n",
              "         [ 66.,  47.,  43.],\n",
              "         [ 64.,  40.,  40.],\n",
              "         [ 58.,  40.,  40.]],\n",
              "\n",
              "        [[ 81.,  76.,  70.],\n",
              "         [ 76.,  71.,  65.],\n",
              "         [ 69.,  62.,  56.],\n",
              "         ...,\n",
              "         [ 57.,  43.,  42.],\n",
              "         [ 71.,  50.,  45.],\n",
              "         [ 67.,  52.,  49.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = cnn.predict(test_image)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LVTNLXcHcwb",
        "outputId": "4563ac35-10b8-4166-cc15-15939c8046aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if result[0][0] == 1:\n",
        "  prediction = 'Cat'\n",
        "else:\n",
        "  prediction = 'Dog'\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rulzLfF3H4oa",
        "outputId": "b55f1543-32b2-4bbb-9ba3-6f4b94efedb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9-gqEosILOu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}